{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from seaborn import heatmap\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import preprocessing and scoring\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from prince import MCA\n",
    "\n",
    "# import models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB, ComplementNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# import misscelaneous\n",
    "from vecstack import StackingTransformer\n",
    "from pycm import ConfusionMatrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redundant Feature Removal and Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YohanJhaveri/Costa-Rica-Housing-Poverty/master/train.csv')\n",
    "\n",
    "# drop columns with missing values\n",
    "df = df.dropna(axis=1, thresh=len(df))\n",
    "\n",
    "# drop columns with ambiguous values\n",
    "df = df.drop(columns = ['dependency', 'edjefe','edjefa'])\n",
    "\n",
    "# group instances by household id (idhogar) and taking the mean of feature values\n",
    "df = df.groupby(['idhogar']).mean()\n",
    "\n",
    "# round the target column after labels have been combined\n",
    "df['Target'] = df['Target'].round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Numerical vs Categorical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = lambda f: (len(set(df[f])) <= 2)\n",
    "\n",
    "def find_categorical():\n",
    "    return filter(lambda f: binary(f) and f != 'Target', df)\n",
    "\n",
    "def find_numerical():\n",
    "    return filter(lambda f: not binary(f) and f != 'Target', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Numerical Data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling and Min-Max Scaling of Numerical Variables\n",
    "\n",
    "def standard_scale():\n",
    "    numerical = find_numerical()\n",
    "\n",
    "    for f in numerical:\n",
    "        mean = np.mean(df[f])\n",
    "        std = np.std(df[f])\n",
    "        df[f] = df[f].apply(lambda x: (x - mean) / std)\n",
    "     \n",
    "    \n",
    "def min_max_scale():\n",
    "    numerical = find_numerical()\n",
    "\n",
    "    for f in numerical:\n",
    "        minimum = min(df[f])\n",
    "        maximum = max(df[f])\n",
    "        df[f] = df[f].apply(lambda x: (x - minimum) / (maximum - minimum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection for Categorical Variables using Gini Index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection for Categorical Variables [GINI INDEX COEFFICIENT]\n",
    "def select_categorical(n):\n",
    "    categorical = find_categorical()\n",
    "    \n",
    "    def gini(array):\n",
    "        array = np.array(array).flatten()\n",
    "        if np.amin(array) < 0: array -= np.amin(array)\n",
    "        array = np.sort(array) * 1.0\n",
    "        index = np.arange(1, array.shape[0]+1)\n",
    "        n = array.shape[0]\n",
    "        return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))\n",
    "    \n",
    "    ginis = [(gini(np.array(df[feature])), feature) for feature in categorical]\n",
    "    \n",
    "    best = set(np.array(sorted(ginis)[:n])[:,-1])\n",
    "    drop = set(categorical).difference(best)\n",
    "    return df.drop(columns=drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection for Numerical Variables [PEARSON CORRELATION MATRIX]\n",
    "def select_numerical(threshold):\n",
    "    numerical = find_numerical()\n",
    "    df_num = df[numerical]\n",
    "\n",
    "    def find_max_corr_col(matrix):\n",
    "        correlations = []\n",
    "        for i, row in enumerate(matrix):\n",
    "            for j, col in enumerate(matrix[row]):\n",
    "                if i != j: correlations.append((abs(col), row))\n",
    "        return max(correlations)\n",
    "\n",
    "    drop = []\n",
    "    max_corr = 1\n",
    "\n",
    "    while True:\n",
    "        matrix = df_num.corr()\n",
    "        max_corr, max_col = find_max_corr_col(matrix)\n",
    "\n",
    "        if max_corr >= threshold: \n",
    "            drop.append(max_col)\n",
    "            df_num = df_num.drop(columns=[max_col])\n",
    "        else: break\n",
    "\n",
    "    return df.drop(columns=drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction for Numerical Variables using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIMENSIONALITY REDUCTION for Numerical Variables\n",
    "def reduce_numerical(n):\n",
    "    numerical = find_numerical()\n",
    "    pca = PCA(n_components=n)\n",
    "    df_num = df[numerical]\n",
    "\n",
    "    components = pca.fit_transform(df_num)\n",
    "\n",
    "    for i in range(n):\n",
    "        df['PCA'+str(i+1)] = components[:,i]\n",
    "\n",
    "    return df.drop(columns=numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction for Categorical Variables using MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIMENSIONALITY REDUCTION for Categorical Variables\n",
    "def reduce_categorical(n):\n",
    "    categorical = find_categorical()\n",
    "    mca = MCA(n_components=n)\n",
    "    df_num = df[categorical]\n",
    "\n",
    "    components = mca.fit_transform(df_num)\n",
    "    \n",
    "    for i in range(n):\n",
    "        df['MCA'+str(i+1)] = components[i]\n",
    "\n",
    "    return df.drop(columns=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing:\n",
    "LIMIT = 50\n",
    "THRESHOLD = 0.8 \n",
    "NUM_N_COMPONENTS = 10\n",
    "NUM_C_COMPONENTS = 10\n",
    "\n",
    "# standard_scale()\n",
    "min_max_scale()\n",
    "df = select_categorical(LIMIT)\n",
    "# df = select_numerical(THRESHOLD)\n",
    "# df = reduce_numerical(NUM_N_COMPONENTS)\n",
    "df = reduce_categorical(NUM_C_COMPONENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.copy().drop(columns=['Target'])\n",
    "y = df[['Target']]\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(model, params): # grid search (using f1-macro as scoring metric and k-fold as cross validation)\n",
    "    rf_grid = GridSearchCV(model, scoring='f1_macro',param_grid = params, cv=KFold(n_splits=3, shuffle=True, random_state=32))\n",
    "    rf_grid.fit(xTrain, yTrain)\n",
    "    return rf_grid.best_params_\n",
    "\n",
    "def predict(model):\n",
    "    model.fit(xTrain, yTrain)\n",
    "    return model.predict(xTest).flatten()\n",
    "\n",
    "def test(model):\n",
    "    yHat = predict(model)\n",
    "    from sklearn import metrics \n",
    "#     return metrics.accuracy_score(yTest, yHat)\n",
    "    return f1_score(yTest, yHat, average='macro')\n",
    "\n",
    "def results(model, params):\n",
    "    optHyper = grid_search(model(), params)\n",
    "    optModel = model(**optHyper)\n",
    "    score = test(optModel)\n",
    "    return optHyper, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding optimum hyperparameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper, score = results(KNeighborsClassifier, {\n",
    "    'n_neighbors': list(range(1, 10))\n",
    "})\n",
    "\n",
    "print('KNN -------------------')\n",
    "print('Hyper:', hyper)\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper, score = results(GaussianNB, {})\n",
    "print('GNB -------------------')\n",
    "print('Hyper:', hyper)\n",
    "print('Score:', score)\n",
    "\n",
    "hyper, score = results(BernoulliNB, {})\n",
    "print('BNB -------------------')\n",
    "print('Hyper:', hyper)\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper, score = results(DecisionTreeClassifier, {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': list(range(1, 30, 5)),\n",
    "    'min_samples_leaf': list(range(1, 30, 5))\n",
    "})\n",
    "\n",
    "print('DT -------------------')\n",
    "print('Hyper:', hyper)\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper, score = results(AdaBoostClassifier, {\n",
    "    'n_estimators': range(1, 50),\n",
    "    'learning_rate': [0.1, 1, 1.5]\n",
    "})\n",
    "\n",
    "print('ADA -------------------')\n",
    "print('Hyper:', hyper)\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper, score = results(XGBClassifier, {\n",
    "    'max_depth': range(30),\n",
    "    'learning_rate': [0.1, 1],\n",
    "    'num_rounds': [1]\n",
    "})\n",
    "\n",
    "print('XGB -------------------')\n",
    "print('Hyper:', hyper)\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_opt = {'learning_rate': 0.1, 'max_depth': 27, 'num_rounds': 10}\n",
    "optXGB = XGBClassifier(**xgb_opt)\n",
    "\n",
    "ada_opt = {'learning_rate': 1.5, 'n_estimators': 49}\n",
    "optADA = AdaBoostClassifier(**ada_opt)\n",
    "\n",
    "optBNB = BernoulliNB()\n",
    "\n",
    "estimators = [('ada', optADA), ('bnb', optBNB)]\n",
    "\n",
    "stack = StackingTransformer(estimators, regression=False, verbose=2)\n",
    "stack = stack.fit(xTrain, yTrain)\n",
    "\n",
    "S_train = stack.transform(xTrain)\n",
    "S_test = stack.transform(xTest)\n",
    "\n",
    "optXGB.fit(S_train, yTrain)\n",
    "yHat = optXGB.predict(S_test)\n",
    "yTest = np.array(yTest).flatten()\n",
    "score = f1_score(yTest, yHat, average='macro')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(estimators=[('xgb', optXGB), ('ada', optADA), ('bnb', optBNB)], voting='hard')\n",
    "ensemble = ensemble1.fit(xTrain, yTrain)\n",
    "ensemble_prediction=ensemble.predict(xTest)\n",
    "score = f1_score(yTest, ensemble1_prediction, average='macro')\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
